\section{Prefix-Doubling}
\label{chapter:saca:doubling}

\subsection{Einleitung}

Viele \currentauthor{Marvin Löbel} der Algorithmen, mit denen Suffix-Arrays berechnet werden, eignen sich nicht dafür, auf externem Speicher zu arbeiten, da sie zu viele I/O-Operationen durchführen würden. Dies macht sie unbrauchbar für große Datenmengen, die nicht vollständig im Hauptspeicher verarbeitet werden können.

Dieses Kapitel präsentiert den in \cite{saca:11} beschriebenen \textbf{Doubling}-Algorithmus und seine verschiedenen Varianten. Er hat die Eigenschaft möglichst effizient bezüglich der I/O-Komplexität zu sein. Er eignet sich auch allgemein als ein Beispiel für einen puren Prefix-Doubling-Ansatz, weshalb wir zum Vergleich mit anderen Algorithmen eine Implementierung nutzen, die nur im Hauptspeicher arbeitet.

\subsection{Grundlagen}

Wir bauen zunächst auf den Prefix-Doubling-Definitionen in \cref{sec:ansatz:doubler} auf. 

Für jeden String $\inputtext$ der Länge $m$ mit beliebigem Alphabet lässt sich ein äquivalenter String $\inputtext'$ mit $\Sigma = [1, m]$ bilden, indem alle vorkommenden Zeichen aufsteigend sortiert, Duplikate entfernt, und die verbleibenden Zeichen durch einen aufsteigenden Zähler ersetzt werden. 

Ein so \textbf{umbenannter} String hat die Eigenschaft, dass die Ordnung über dem neuen Alphabet identisch zu der über dem ursprünglichen ist und sich somit darauf dasselbe Suffix-Array ergibt. Ein dazu ähnliches Verfahren, die \textbf{lexikographische Umbenennung}, wird Kern der vorgestellten Algorithmen sein und beruht darauf ganze (Teil-)Strings eines Textes durch aufsteigende Zähler zu ersetzen.

Für die Analyse der Zugriffsoperationen auf externen Speicher betrachten wir das I/O-Model \cite{Vitter1994}. Darin besteht ein Computersystem aus $M$ Wörtern schnellen Hauptspeichers und langsameren externen Speicher der sich über I/O-Operationen in Blockgrößen $B$ über $D$ Platten erstreckt. Für Eingaben der Länge $n$ nehmen wir eine Wortbreite $\geq \ceil*{\log n}$ Bits an. Wir definieren folgende Kurzschreibweisen:
\begin{itemize}
\item $\text{scan}(x) = \ceil*{x/DB}$ für sequentielles Lesen oder Schreiben von $x$ Wörtern in externen Speicher.
\item $\text{sort}(x) = \frac{2x}{DB}\ceil*{\log_{M/B}\frac{x}{M}}$ für das I/O-effiziente Sortieren von $x$ Wörtern unter Zuhilfenahme von externen Speicher.
\end{itemize}

\subsection{Überblick}

Wir betrachten zunächst in Abschnitt \ref{algo:doubling:sec:doubling} den Doubling-Algorithmus \cite{Arge1997}\cite{Crauser2002}. Dieser hat eine I/O-Komplexität von $\mathcal{O}(\text{sort}(n \log \text{maxlcp}))$ und erlaubt es Strings der Länge $2^k$ in $k$ Iterationen zu sortieren.

In den nachfolgenden Abschnitten werden wir anschließend systematisch Modifikationen einführen, die den Algorithmus bezüglich I/O-Komplexität und Rechenaufwand verbessern. Wir beginnen in Abschnitt \ref{algo:doubling:sec:pipelining} mit dem Konzept des \textit{Pipelining}s, welches auf externen Algorithmen in der Regel eine I/O-Reduzierung um den Faktor 2 ermöglicht.

Abschnitt \ref{algo:doubling:sec:discarding} beschreibt eine simple Methode, bereits bestimmte Suffixe aus nachfolgenden Iterationen des Doubling-Algorithmus zu entfernen (\textit{Discarding}). Dies verbessert die I/O-Komplexität gegenüber Doubling zu\newline $\mathcal{O}(\text{sort}(n \log \text{dps}))$ und ist besser als vorherige Discarding-Ansätze mit einer Komplexität von $\mathcal{O}(\text{sort}(n \log \text{dps})) + \text{scan}(n \log \text{maxlcp})$ \cite{Crauser2002}.

Abschnitt \ref{algo:doubling:sec:tupling} beschreibt eine Laufzeitverbesserung um einen konstanten Faktor, bei dem Strings der Länge $a^k$ in $k$ Iterationen sortiert werden (\textit{$a$-Tupling}). Es stellen sich hierbei $a = 4$ und $a = 5$ als beste Ergebnisse heraus.

Abschnitt \ref{algo:doubling:sec:summary} fasst die einzelnen Varianten zusammen und gibt einen Überblick darüber welchen Nutzen sie für andere Algorithmen haben können.

\subsection{Prefix-Doubling}
%captionpos=t,float,abovecaptionskip=-\medskipamount
\label{algo:doubling:sec:doubling}
\begin{listing}[htp]
\begin{minted}[escapeinside=@@,numbers=left]{python}
def doubling(T):
  S = [((T[i], T[i + 1]), i) for i in @$[0, n)$@]
  for k in @$[1, \ceil*{\log_2 n}]$@:
    @sort@ S
    P = name(S)
    if @names in $P$ are unique@:
      return [i for (c, i) in P]
    @sort@ P @by $(i \mod 2^k, i \div 2^k)$@
    S = []
    for each @$(d, i) = P[j]$@:
      if @$(d^\prime, i^\prime) = P[j + 1]$@ exists and @$i + 2^k == i^\prime$@:
        append ((@$d$@, @$d^\prime$@), i) to S
      else:
        append ((@$d$@, @$\$$@), i) to S
def name(S):
  q = 0
  r = 0
  (@$l,l^\prime$@) = (@$\$$@, @$\$$@)
  result = []
  for ((@$c,c^\prime$@), i) in S:
    q = q + 1
    if (@$c,c^\prime$@) != (@$l,l^\prime$@):
      r = q
      (@$l,l^\prime$@) = (@$c,c^\prime$@)
    append (r, i) to result
  return result
\end{minted}
\caption{Doubling} 
\label{algo:doubling:code:doubling}
\end{listing}

Wie in \cref{sec:ansatz:doubler} beschrieben, sortieren wir alle $\inputtext_i$ anhand eines Präfixes von $2^k$ Zeichen. Wir vergleichen die $\inputtext{}[i, i + 2^k)$ Strings jedoch nicht zeichenweise, da dies den Rechenaufwand mit jedem Iterationsschritt verdoppeln würde. Stattdessen arbeitet der Algorithmus auf einer Sequenz $S$ von Tupeln $((c, c'), i)$, bei der $c$ und $c'$ eindeutige \textbf{Namen} für $\inputtext{}[i, i + 2^{k-1})$ und $\inputtext{}[i + 2^{k-1}, i + 2^k)$ sind. Eine naive Implementierung dieses Ansatzes findet sich unter \texttt{doubling()} in Algorithmus \ref{algo:doubling:code:doubling}.

\begin{figure}
\begin{tikzpicture}[cell/.style={rectangle,draw=black},
space/.style={minimum height=1.5em,matrix of nodes,row sep=-\pgflinewidth,column sep=-\pgflinewidth,column 1/.style={font=\ttfamily}},text depth=0.5ex,text height=2ex,nodes in empty cells]

\matrix (first) [space, column 1/.style={font=\ttfamily},column 2/.style={nodes={cell,minimum width=5.5em}}]
{
& $((a, b), 0)$ \\ 
& $((b, r), 1)$ \\ 
& $((r, a), 2)$ \\ 
& $((a, c), 3)$ \\ 
& $((c, a), 4)$ \\ 
& $((a, d), 5)$ \\ 
& $((d, a), 6)$ \\ 
& $((a, b), 7)$ \\ 
& $((b, r), 8)$ \\ 
& $((r, a), 9)$ \\ 
& $((a, \$), 10)$ \\ 
};

\matrix (second) [right=0.5em of first, space, column 1/.style={font=\ttfamily},column 2/.style={nodes={cell,minimum width=5.5em}}]
{
& $((a, \$), 10)$ \\ 
& $((a, b), 0)$ \\ 
& $((a, b), 7)$ \\ 
& $((a, c), 3)$ \\ 
& $((a, d), 5)$ \\ 
& $((b, r), 1)$ \\ 
& $((b, r), 8)$ \\ 
& $((c, a), 4)$ \\ 
& $((d, a), 6)$ \\ 
& $((r, a), 2)$ \\ 
& $((r, a), 9)$ \\ 
};

\matrix (third) [right=0.5em of second, space, column 1/.style={font=\ttfamily},column 2/.style={nodes={cell,minimum width=5.5em}}]
{
& $(1, 10)$ \\ 
& $(2, 0)$ \\ 
& $(2, 7)$ \\ 
& $(4, 3)$ \\ 
& $(5, 5)$ \\ 
& $(6, 1)$ \\ 
& $(6, 8)$ \\ 
& $(8, 4)$ \\ 
& $(9, 6)$ \\ 
& $(10, 2)$ \\ 
& $(10, 9)$ \\ 
};

\matrix (fourth) [right=0.5em of third, space, column 1/.style={font=\ttfamily},column 2/.style={nodes={cell,minimum width=5.5em}}]
{
& $(2, 0)$ \\ 
& $(10, 2)$ \\ 
& $(8, 4)$ \\ 
& $(9, 6)$ \\ 
& $(6, 8)$ \\ 
& $(1, 10)$ \\ 
& $(6, 1)$ \\ 
& $(4, 3)$ \\ 
& $(5, 5)$ \\ 
& $(2, 7)$ \\ 
& $(10, 9)$ \\ 
};

\matrix (fift) [right=0.5em of fourth, space, column 1/.style={font=\ttfamily},column 2/.style={nodes={cell,minimum width=5.5em}}]
{
& $((2, 10), 0)$ \\ 
& $((10, 8), 2)$ \\ 
& $((8, 9), 4)$ \\ 
& $((9, 6), 6)$ \\ 
& $((6, 1), 8)$ \\ 
& $((1, \$), 10)$ \\ 
& $((6, 4), 1)$ \\ 
& $((4, 5), 3)$ \\ 
& $((5, 2), 5)$ \\ 
& $((2, 10), 7)$ \\ 
& $((10, \$), 9)$ \\ 
};


\newcommand{\tbc}[4]{
\draw[decorate,decoration={brace,amplitude=3pt,mirror}] 
    ($(text-1-#1.south west) - (0, #4)$) -- ($(text-1-#2.south east) - (0, #4)$);
\node at ($(text-1-#1)!0.5!(text-1-#2) - (0, 1.7em) - (0, #4)$) {#3};
}

\matrix (text) [above=5em of third, space, nodes={cell,minimum width=2em}]
{
a&b&r&a&c&a&d&a&b&r&a&\$ \\
};
\node [right of=text-1-12] {\dots};
\node (textlable) [left of=text-1-1] {$T$:};
\node [below=0.6em of textlable] {$P^k$:};
\node (tl1) [above=0 of first] {$S^k$};
\node (tl2) [above=0 of second] {$S^k$};
\node (tl3) [above=0 of third] {$P^k$};
\node (tl4) [above=0 of fourth] {$P^k$};
\node (tl5) [above=0 of fift] {$S^{k+1}$};
\draw [very thick] (fourth-6-2.south west) -- (fourth-6-2.south east);

\node [right=0 of fift] {\dots};

\node[single arrow, single arrow head extend=0.25em, draw=black, fill=gray!50, minimum height=40] at($(tl1)!0.5!(tl2)$) {sort};
\node[single arrow, single arrow head extend=0.25em, draw=black, fill=gray!50, minimum height=40] at($(tl3)!0.5!(tl4)$) {sort};

\node[single arrow, single arrow head extend=0.25em, draw=black, fill=gray!50, minimum height=40] at($(tl2)!0.5!(tl3)$) {name};
\node[single arrow, single arrow head extend=0.25em, draw=black, fill=gray!50, minimum height=40] at($(tl4)!0.5!(tl5)$) {pair};
\node[single arrow, single arrow head extend=0.25em, draw=black, fill=gray!50, minimum height=40] at($(tl4)!0.5!(tl5)$) {pair};
      
\tbc{1}{2}{2}{0.1em}
\tbc{3}{4}{10}{0.1em}
\tbc{5}{6}{8}{0.1em}
\tbc{7}{8}{9}{0.1em}
\tbc{9}{10}{6}{0.1em}
\tbc{11}{12}{1}{0.1em}

\tbc{2}{3}{6}{1.5em}
\tbc{4}{5}{4}{1.5em}
\tbc{6}{7}{5}{1.5em}
\tbc{8}{9}{2}{1.5em}
\tbc{10}{11}{10}{1.5em}
\end{tikzpicture}
\caption{\texttt{doubling()} für $\inputtext{}$ = \textit{abracadabra} und $k = 1$}
\label{algo:doubling:fig:doubling}
\end{figure}

Wir betrachten hierfür das Beispiel in Abbildung \ref{algo:doubling:fig:doubling}. Zu Beginn der ersten Iteration entsprechen $c$ und $c'$ benachbarten Zeichen im Eingabestring. $S$ wird gemäß der $(c, c')$-Tupel lexikografisch sortiert (erster \textit{sort}-Schritt im Beispiel), und anschließend gemäß ihrer neuen Position in $S$ \textbf{lexikographisch umbenannt} (\textit{name} im Beispiel).

Die Umbenennung erfolgt, indem die Tupel durch Zeichen $d$ aus $[1, n]$ ersetzt werden, die derselben aufsteigenden Ordnung folgen. Siehe hierzu die \texttt{name()}-Funktion in Algorithmus \ref{algo:doubling:code:doubling}. Die erhaltenen Tupel $(d, i)$ werden in eine Sequenz $P$ eingefügt und haben die Eigenschaft, dass $d$ jeweils ein eindeutiger Name für die Zeichenfolge $\inputtext{}[i, i + 2^k)$ ist. Dies lässt sich gut an der Abbildung veranschaulichen, in der die Namen $d$ aller $(d, i) \in P^k$ zusätzlich an ihren Textpositionen $i$ unter der Eingabe $\inputtext{}$ eingezeichnet sind. So haben zum Beispiel die Länge-2-Teilstrings an Postion 2 und 9 beide den Namen 10.

Die $P$-Sequenz wird anschließend gemäß des Tupels $(i \mod 2^k, i \div 2^k)$ lexikografisch sortiert (zweiter \textit{sort}-Schritt im Beispiel). Dies führt dazu, dass Namen für direkt benachbarte Teilstrings in $P$ nebeneinander liegen und Namen für überlappende Teilstrings in separaten Abschnitten von $P$ liegen. Dies wird in der Abbildung durch die schwarze Trennlinie im zweiten $P^k$-Array deutlich.

$P$ wird nun ähnlich zur Eingabezeichenfolge betrachtet, indem aus benachbarten Namen $d$ und $d'$ Tupel $((d, d'), i)$ gebildet werden und diese als Sequenz $S$ für die nächste Iteration genutzt werden (\textit{pair} im Beispiel).

Da immer nur zwei Namen für benachbarte Teilstrings zu neuen Namen zusammengefasst werden und der Algorithmus mit allen Zeichen und Textpositionen der Eingabe beginnt, verdoppelt sich somit in jeder Iteration die Länge der repräsentierten Präfixe des Suffix-Arrays. Da die Ordnung der darunterliegenden Strings in den neuen Namen erhalten bleibt, lässt sich aus $S$-Sequenzen von späteren Iterationen das korrekte Suffix-Array auslesen, sobald alle Elemente in ihnen eindeutig sind. Und da in jeder Iteration immer nur Paare von Namen betrachtet werden, steigen die Sortierkosten von $S$ nicht mit jeder Iteration.

Wir gehen nun davon aus, dass $S$ und $P$ in externem Speicher liegen. Gemäß unserer Definition zur I/O-Komplexität, führt der Algorithmus pro Iteration einen konstante Anzahl von \textit{Scanning}- und \textit{Sort}-Operationen über $n$ Elemente durch und hat eine obere Iterationsschranke beim Logarithmus des längsten gemeinsamen Präfixes. Es gilt somit:

\begin{theorem}
Der Doubling-Algorithmus berechnet ein Suffix-Array in\\ $\mathcal{O}(\text{sort}(n) \ceil*{\log \text{maxlcp}})$ I/O-Operationen.
\end{theorem}

\subsection{Pipelining}
\label{algo:doubling:sec:pipelining}

Als erste signifikante Verbesserung des Doubling-Algorithmus beobachten wir, dass sich manche Operation auf $P$ und $S$ beschleunigen lassen, indem sie temporäre Daten, anstatt sie erst in eine Sequenz zu schreiben und anschließend wieder auszulesen, direkt aneinander weitergeben (\textbf{Pipelining}). 

Wir betrachten hierzu wieder Algorithmus \ref{algo:doubling:code:doubling}. Anstatt die Tupel in Zeile (2) zunächst vollständig in $S$ zu schreiben, können sie direkt an die Sortierfunktion in Zeile (4) übergeben werden. Ebenso können die so sortierten Tupel direkt in die Benennungsfunktion in Zeile (5), und von dort direkt in die Sortierfunktion in Zeile (8) geleitet werden, da sich die Benennungsfunktion nur jeweils das vorherige Tupel merken muss. Dasselbe gilt für die Paarbildung in den Zeilen (10)--(14), in der auch nur jeweils zwei nachfolgende Elemente betrachtet werden müssen. Die in Zeile (12) und (14) bestimmten Tupel können schließlich wie in Zeile (2) direkt in die Sortierfunktion (4) der nächsten Iteration geleitet werden.

Wir analysieren diese Modifikation nun genauer in Hinblick auf die I/O-Komplexität. Wir nehmen zunächst an, dass sich eine Sequenz aus $m$ Wörtern mit einem geeigneten Sortieralgorithmus in $\approx 4m/DB$ I/O-Operationen und mit zwei Durchläufen sortieren lässt, falls $x \ll M^2/DB$ und $M \gg DB$ \cite{Aggarwal1988}. Die folgende Analyse ist dabei \cite{saca:11} entnommen.

Ohne Pipelining benötigt die Sortierung von $n$ Tripeln in Zeile (4) somit $12m/DB$ I/Os, und das Lesen der Tripel und Schreiben der Paare in Zeile (5) $5m/DB$ I/Os. Der Test auf Eindeutigkeit in Zeile (6) kann während der Benennung durchgeführt werden und benötigt keine zusätzlichen I/Os. Das Sortieren der Tupel in Zeile (8) kostet $8m/DB$ I/Os, und das Lesen der Paare und Schreiben der Tripel in Zeilen (10)--(14) wiederum  $5m/DB$ I/Os. Insgesamt erhalten wir somit Kosten von $(12 + 5 + 8 +5)n/DB = 30n/DB$ I/Os.

Wir betrachten nun die I/Os für die Pipelining-Variante des Algorithmus. Zunächst können die $S$-Tupel direkt in die erste Phase des Sortieralgorithmus (Zeile (4)) geleitet werden, welche dabei mit $3n/DB$ I/Os in externen Speicher schreibt. Die zweite Phase liest die Tripel sortiert in ebenfalls $3n/DB$ I/Os aus, und leitet sie ohne weitere I/Os durch die Benennungsfunktion und in die erste Phase der Sortierung in Zeile (8). Diese schreibt mit $2n/DB$ I/Os, und liest sie in der zweiten Phase mit $2n/DB$ I/Os sortiert aus, leitet sie ohne zusätzliche I/Os durch die Paarbildung, und übergibt sie an die erste Phase der $S$-Sortierung der nächsten Iteration. 

Insgesamt wurden somit innerhalb der Iterationen alle \textit{Scan}-Operationen von $S$ und $P$ eliminiert und nur die Hälfte der I/Os von \textit{Sort}-Operationen beibehalten, womit sich insgesamt eine Reduzierung auf $(3 + 3 + 2 + 2)n/DB = 10n/DB$ I/Os ergibt. Dies erlaubt eine genauere Spezifizierung der I/O-Komplexität des Algorithmus:

\begin{theorem}
Der Doubling-Algorithmus mit Pipelining berechnet ein Suffix-Array in $\text{sort}(5n) \ceil*{\log \text{maxlcp}} +  \mathcal{O}(\text{sort}(n))$ I/O-Operationen.
\end{theorem}

Der $\mathcal{O}(\text{sort}(n))$ Anteil steht hierbei für alle einmalig durchzuführenden Berechnungen außerhalb der Schleife.

\subsection{Discarding}
\label{algo:doubling:sec:discarding}

\begin{listing}[htp]
%captionpos=t,float,abovecaptionskip=-\medskipamount
\begin{minted}[escapeinside=@@,numbers=left]{python}
def doubling_discarding(T):
  S = [((T[i], T[i + 1]), i) for i in @$[0, n)$@]
  @sort@ S
  U = name(S) # undiscarded
  P = []      # partially discarded
  F = []      # fully discarded
  for k in @$[1, \ceil{\log_2 n}]$@:
    @mark unique names in@ U
    @sort@ U @by $(i \mod 2^k, i \div 2^k)$@
    @merge@ P @into@ U
    P = []
    S = []
    count = 0
    for each @$(d, i)$ = U[j]@:
      if @$(d, i)$@ is unique:
        if count < 2:
          append (@$d, i$@) to F
        else:
          append (@$d, i$@) to P
        count = 0
      else:
        if @$(d^\prime, i^\prime) = U[j + 1]$@ exists and @$i + 2^k == i^\prime$@:
          append ((@$d$@, @$d^\prime$@), i) to S
        else:
          append ((@$d$@, @$\$$@), i) to S
        count = count + 1
    if S @is empty@:
      @sort@ F
      return [i for (d, i) in F]
    @sort@ S
    U = name2(S)
def name2(S):
  q = 0
  r = 0
  (@$l,l^\prime$@) = (@$\$,\$$@)
  result = []
  for ((@$c,c^\prime$@), i) in S:
    if @$c$@ != @$l$@:
      (q, r) = (0, 0)
      (@$l,l^\prime$@) = (@$c,c^\prime$@)
    elif @$c^\prime$@ != @$l^\prime$@:
      r = q
      @$l^\prime$@ = @$c^\prime$@
    append (@$c$@ + r, i) to result
    q = q + 1
  return result
\end{minted}
\caption{Doubling+Discarding} 
\label{algo:doubling:code:discarding}
\end{listing}

Für die nächste Verbesserung des Algorithmus beobachten wir Folgendes. Sei $c_i^k$ der lexikographische Name für ein $\inputtext{}[i, i + 2^k)$ in Iteration $k$. Falls $c_i^k$ einzigartig in $S$ ist, ist auch der zugehörige Teilstring ein einzigartiger Präfix. Es gilt somit $c_i^k = c_i^h$ für alle $h > k$, da die zusätzlichen Zeichen in $\inputtext{}[i, i + 2^h)$ nichts mehr an der lexikografischen Sortierung und somit der Position in $S$ ändern würden. Die Idee des \textbf{Discardings} ist es nun, in jeder Iteration Tupel mit einzigartigen Namen aus $S$ zu entfernen, um somit nachfolgende I/Os zu verringern. 

Ein Problem hierbei ist, dass sich durch das Entfernen von Elementen aus $S$ die Benennungsfunktion \texttt{name()} anders verhalten würde, da ein Name durch die Anzahl vorheriger Tupel bestimmt wird. Dies macht eine neue Funktion \texttt{name2()} erforderlich, die bei der Benennung von allen $(c, c') \in S$ Namen relativ zum numerischen Wert von $c$ bildet. Siehe Algorithmus \ref{algo:doubling:code:discarding} für eine entsprechende Implementierung.

Es dürfen außerdem nicht alle einzigartigen $c_i^k$ direkt aus $S$ entfernt werden, da sie gegebenenfalls noch mit benachbarten Namen gepaart werden müssen. Hierzu betrachten wir die Situation für $c_i^{k+1}$, und unterscheiden zwei Fälle: Falls einer der vorherigen Namen $c_{i - 2^k}^k$ oder $c_{i - 2^{k+1}}^k$ einzigartig ist, gilt dies auch für ihre Zusammenführung in $c_{i - 2^{k+1}}^{k+1}$. Somit ist $c_i^{k+1}$ nicht notwendig, um $c_{i - 2^{k+1}}^{k+2}$ als einzigartig zu identifizieren und kann aus $S$ entfernt werden. Wir bezeichnen dies als \textit{Fully-Discarded}. Ansonsten ist $c_{i - 2^{k+1}}^{k+1}$ nicht einzigartig und wir benötigen $c_i^{k+1}$, um $c_{i - 2^{k+1}}^{k+2}$ zu bestimmen. Wir entfernen $c_i^k$ weiterhin aus $S$, aber übernehmen es zunächst noch als $d = c_i^{k+1}$ in die Liste der sortierten $(d, i)$ Paare der nächsten Iteration. Wir bezeichnen dies als \textit{Partially-Discarded}.

Alle Tupel, die vollständig aus $S$ entfernt wurden, werden in einer zusätzlichen Sequenz $F$ gesammelt und der Algorithmus endet sobald $S$ leer ist. Wenn dies der Fall ist, enthält $F$ einen eindeutigen Namen für jede Textposition und es lässt sich nach einer finalen lexikografischen Sortierung das Suffix-Array auslesen. Siehe hierzu \texttt{doubling\_discarding()} in Algorithmus \ref{algo:doubling:code:discarding}.

Wir betrachten nun wieder die I/O-Komplexität. Der naive Doubling-Algorithmus sortiert und verdoppelt so lange alle Präfixe, bis sie paarweise verschieden sind. Jeder einzelne Präfix durchläuft somit immer genau $\log \text{maxlcp}$ Iterationen. Mit Discarding hingegen wird ein einzigartiger Präfix so früh wie möglich aus der Iteration entfernt. Somit gilt für alle $\suffix i$, dass ein Präfix maximal $\text{dps}(i)$ Iterationen durchläuft.

Wir stellen auch fest, dass Discarding kompatibel mit Pipelining ist. Der Algorithmus nutzt zwar mehr (externe) Sequenzen von Tupeln, aber es werden weiterhin in $k$ Iterationen jeweils nur die zwei \textit{Sort}-Operationen des Basisalgorithmus angewandt und alle weiteren Operationen scannen die einzelnen Elemente jeweils nur in einem Durchlauf. Dies ermöglicht somit das direkte Weiterleiten von Zwischenergebnissen in Form von Pipelining und führt zu folgender Analyse der Gesamtkomplexität:

\begin{theorem}
Der Doubling-Algorithmus mit Pipelining und Discarding berechnet ein Suffix-Array in $\text{sort}(5n) \ceil*{\log \text{dps}} +  \mathcal{O}(\text{sort}(n))$ I/O-Operationen.
\end{theorem}

\subsection{A-Tupling}
\label{algo:doubling:sec:tupling}
\begin{listing}[htp]
%captionpos=t,float,abovecaptionskip=-\medskipamount
\begin{minted}[escapeinside=@@,numbers=left]{python}
def a_tupling(T):
  S = [((T[i], T[i + 1], @\dots@, T[i + a - 1]), i) for i in @$[0, n)$@]
  for k in @$[1, \ceil{\log_a n}]$@:
    @sort@ S
    P = name(S)
    if @names in $P$ are unique@:
      return [i for (c, i) in P]
    @sort@ P @by $(i \mod a^k, i \div a^k)$@
    S = []
    for each @$(d, i)$ = P[j]@:
      l = @$i$@
      T = [@$d$@]
      for q in @$[1, a - 1]$@:
        if @$(d^\prime, i^\prime) = P[j + q]$@ exists and @$l + a^k == i^\prime$@:
          append @$d^\prime$@ to T
        else:
          append @$\$$@ to T
        l = @$i^\prime$@
      append (T, i) to S
\end{minted}
\caption{$a$-Tupling} 
\label{algo:doubling:code:atupling}
\end{listing}

Als letzte Verbesserung lässt sich der Doubling-Algorithmus schließlich darauf generalisieren, in jeder Iteration lexikografische Namen für $a^k$ Zeichen, anstatt $2^k$ zu bestimmen. Hierzu werden jeweils $a$ benachbarte Namen in einem Tupel gesammelt. Algorithmus \ref{algo:doubling:code:atupling} zeigt den so modifizierten Code ohne Discarding oder Pipelining.

Dies wirkt sich in zwei Aspekten auf die I/O-Komplexität aus. Anstatt $\text{sort}(5n)$ Sortieroperationen pro Iteration, erhöhen sich die Kosten auf $\text{sort}((a+3)n)$. Andererseits verringert sich die Anzahl der Iterationen auf $\log_a n$. Setzt man beide Werte in Relation zueinander, so erhält man einen Faktor von $\frac{a + 3}{\log a}$ für die gesamten I/O-Kosten des Algorithmus. 

\begin{table}
\centering
\begin{tabular}{cccccc}
\toprule
$a$ & 2 & 3 & 4 & 5 & 6 \\ 
\midrule 
$(a+3) / \log a$ & $5,0$ & $3,78$ & $3,50$ & $3,45$ & $3,56$ \\ 
\bottomrule
\end{tabular} 
\caption{I/O-Anforderungen für verschiedenen Varianten von $a$-Tupling}
\label{algo:doubling:tab:tab1}
\end{table}

Werten wir dies für unterschiedliche Werte von $a$ aus, so ist $a = 5$ optimal (Siehe Tabelle \ref{algo:doubling:tab:tab1}). In der Praxis eignet sich jedoch $a = 4$ mehr, da die I/O-Kosten nur $1,5\%$ schlechter sind und sich der Wert als Zweierpotenz besser für Berechnungen und der Implementierung eignet.

Der $a$-Tupling Ansatz lässt sich ohne signifikante Anpassungen in der Discarding und Pipelining-Variante verwenden, womit sich die folgenden I/O-Komplexitäten direkt ableiten lassen:

\begin{theorem}
Der Doubling-Algorithmus mit Pipelining und $a$-Tupling berechnet ein Suffix-Array in $\text{sort}(\frac{a + 3}{\log a}n) \ceil*{\log \text{maxlcp}} +  \mathcal{O}(\text{sort}(n))$ I/O-Operationen.
\end{theorem}

\begin{theorem}
Der Doubling-Algorithmus mit Pipelining, $a$-Tupling und Discarding berechnet ein Suffix-Array in $\text{sort}(\frac{a + 3}{\log a}n) \ceil*{\log \text{dps}} +  \mathcal{O}(\text{sort}(n))$ I/O-Operationen.
\end{theorem}

\subsection{Zusammenfassung und Ausblick}
\label{algo:doubling:sec:summary}

In den vorhergehenden Abschnitten haben wir den Doubling-Algorithmus betrachtet und die darauf aufbauenden Modifikationen Pipelining, Discarding und $a$-Tupling. Jede dieser drei Varianten verbessert die I/O-Komplexität des Basisalgorithmus und lässt sich mit den anderen Kombinieren, wodurch sich ein guter externer Suffix-Array-Algorithmus definieren lässt, der alle Varianten miteinander vereint.

Das Pipelining beschreibt insbesondere eine allgemeine Technik, die auch für viele andere Algorithmen auf externen Speicher nützlich ist. Ebenso existieren weiterführende Algorithmen, die auf Präfix Doubling aufbauen. Ein Beispiel hierfür ist der DC3 und DCX Algorithmus \cite{saca:11}. Siehe auch \cref{algorithm:dc3}.

\subsection{Implementierung}
Die Implementierung als Teil des Benchmarking-Frameworks erfolgt aus Gründen der Vergleichbarkeit nicht im externen Speicher. Stattdessen sind die in den Algorithmen benutzten $P$-, $S$-, $U$- und $F$-Arrays grundsätzlich mit der vom Framework bereitgestellten \texttt{container} Klasse implementiert.

Dies hat auch Auswirkungen auf den Sortieralgorithmus und die Anwendbarkeit des Pipelinings. Da nun davon ausgegangen wird, dass jedes Array immer in den Hauptspeicher passt, ist man somit nicht mehr auf einen effizienten externen Mergesort angewiesen und kann einen beliebigen In-Memory-Sortierer benutzen. 

Dies verhindert jedoch ein direktes Anwenden des Pipelining-Ansatzes im vorgestellen Sinne, da die Sortierschritte in den Algorithmen nicht mehr als Stream-akzeptierend bzw. -erzeugend betrachtet werden können. Aufgrund des Fehlens von IO-Operationen auf externen Speicher hat dies allerdings auch geringe Auswirkungen. In \cref{algo:doubling:sec:usedoptimizations} nutzen wir stattdessen die Pipelining-Idee dafür, den Speicherverbrauch der Arrays stark zu senken.

\subsubsection{Umsetzung}
\label{chapter:saca:doubling:memory}

Die Implementierung besteht aus einer C++-Klasse, die über dem benutzten \texttt{sa\_index}-Typ und der Tupelgröße \texttt{a} gemäß des $a$-Tuplings templatisiert ist.

Diese stellt die statischen Memberfunktionen \texttt{doubling()} und\linebreak \texttt{doubling\_discarding()} bereit, die den normalen Doubling-Algorithmus bzw. seine Discarding-Variante abhängig von \texttt{a} implementieren.

Sie nutzen dabei das vom Framework vorgegebene Interface, bei dem die Eingabe als ein \texttt{string\_span} repräsentiert wird, der auf einen Bereich im Speicher zeigt und das Ausgabe-Array \sa als ein \texttt{util::span<sa\_index>} repräsentiert wird, in das geschrieben werden muss.

Die Arrays enthalten Tupel der Form  $(c, i)$ und $((c_1, \dots, c_a), i)$, wobei $c$ ein Präfixname ist, und $i$ ein Textindex. Da sowohl Namen als auch Indexe in $[0, n)$ liegen, passen alle Werte in eine Variable vom Typ \texttt{sa\_index} (siehe \cref{sec:code-structure}). Die Implementierung repräsentiert deshalb alle Tupel als Arrays fester Länge \texttt{std::array<sa\_index, 2>} bzw. \texttt{std::array<sa\_index, a + 1>}.

Sei $w = \texttt{sizeof(sa\_index)}$. Bei einer direkten Umsetzung der Algorithmen in C++ liegt der zusätzliche Speicherverbrauch des normalen Doublings somit bei $(a + 3)nw$ Bytes, und der der Discarding-Variante bei $(a + 7)nw$ Bytes. Siehe \cref{fig:doubling:opt:basic} und \cref{fig:doubling:opt:discard}.

% Logical width
\def\pdew{26}

\begin{figure}
\begin{tikzpicture}[yscale=-1,xscale=\textwidth/(\pdew cm + 1cm)]

% Arrays
\draw [black,fill=blue!20] (2, 0) rectangle coordinate (P1) ($(\pdew, 2)$);
\draw [black,fill=green!20] (2, 2) rectangle coordinate (S1) ($(\pdew, 6)$);

% Komponents
\draw [black] (0, 0) rectangle coordinate (cP1) (2, 1);
\draw [black] (0, 1) rectangle coordinate (iP1) (2, 2);

\draw [black] (0, 2) rectangle coordinate (cS1) (2, 5);
\draw [black] (0, 5) rectangle coordinate (iS1) (2, 6);

% Komponent lines
\draw [dashed] (2,1) -- (\pdew,1);
\draw [dashed] (2,3) -- (\pdew,3);
\draw [dashed] (2,4) -- (\pdew,4);
\draw [dashed] (2,5) -- (\pdew,5);

% Labels
\node[fill=blue!20] at (P1) {$P$};
\node[fill=green!20] at (S1) {$S$};

\node[fill=white] at (cP1) {$c$};
\node[fill=white] at (iP1) {$i$};

\node[fill=white] at ($(cS1) - (0, 1)$)  {$c_1$};
\node[fill=white] at (cS1) {$\vdots$};
\node[fill=white] at ($(cS1) + (0, 1)$)  {$c_a$};
\node[fill=white] at (iS1) {$i$};

% Braces
\draw[decoration={brace,amplitude=10pt,raise=2pt},decorate]
  (2,0) -- node[above=12pt] {$n$} (\pdew,0);
  
\draw[decoration={brace,amplitude=5pt,raise=2pt},decorate]
  (\pdew,0) -- node[right=7pt] {$w$} (\pdew,1);

\end{tikzpicture}
\caption{Doubling-Speicherlayout}
\label{fig:doubling:opt:basic}
\end{figure}

\begin{figure}
\begin{tikzpicture}[yscale=-1,xscale=\textwidth/(\pdew cm + 1cm)]

% Arrays
\draw [black,fill=green!20] (2, 0) rectangle coordinate (S1) ($(\pdew, 4)$);
\draw [black,fill=yellow!20] (2, 4) rectangle coordinate (U1) ($(\pdew, 6)$);
\draw [black,fill=blue!20] (2, 6) rectangle coordinate (P1) ($(\pdew, 8)$);
\draw [black,fill=red!20] (2, 8) rectangle coordinate (F1) ($(\pdew, 10)$);

% Komponents
\draw [black] (0, 6) rectangle coordinate (cP1) (2, 7);
\draw [black] (0, 7) rectangle coordinate (iP1) (2, 8);

\draw [black] (0, 0) rectangle coordinate (cS1) (2, 3);
\draw [black] (0, 3) rectangle coordinate (iS1) (2, 4);

\draw [black] (0, 4) rectangle coordinate (cU1) (2, 5);
\draw [black] (0, 5) rectangle coordinate (iU1) (2, 6);

\draw [black] (0, 8) rectangle coordinate (cF1) (2, 9);
\draw [black] (0, 9) rectangle coordinate (iF1) (2, 10);

% Komponent lines
\draw [dashed] (2,0) -- (\pdew,0);
\draw [dashed] (2,1) -- (\pdew,1);
\draw [dashed] (2,2) -- (\pdew,2);
\draw [dashed] (2,3) -- (\pdew,3);
\draw [dashed] (2,4) -- (\pdew,4);
\draw [dashed] (2,5) -- (\pdew,5);
\draw [dashed] (2,6) -- (\pdew,6);
\draw [dashed] (2,7) -- (\pdew,7);
\draw [dashed] (2,8) -- (\pdew,8);
\draw [dashed] (2,9) -- (\pdew,9);
\draw [dashed] (2,10) -- (\pdew,10);

% Labels
\node[fill=blue!20] at (P1) {$P$};
\node[fill=green!20] at (S1) {$S$};
\node[fill=yellow!20] at (U1) {$U$};
\node[fill=red!20] at (F1) {$F$};

\node[fill=white] at (cP1) {$c$};
\node[fill=white] at (iP1) {$i$};
\node[fill=white] at (cU1) {$c$};
\node[fill=white] at (iU1) {$i$};
\node[fill=white] at (cF1) {$c$};
\node[fill=white] at (iF1) {$i$};

\node[fill=white] at ($(cS1) - (0, 1)$)  {$c_1$};
\node[fill=white] at (cS1) {$\vdots$};
\node[fill=white] at ($(cS1) + (0, 1)$)  {$c_a$};
\node[fill=white] at (iS1) {$i$};

% Braces
\draw[decoration={brace,amplitude=10pt,raise=2pt},decorate]
  (2,0) -- node[above=12pt] {$n$} (\pdew,0);
  
\draw[decoration={brace,amplitude=5pt,raise=2pt},decorate]
  (\pdew,0) -- node[right=7pt] {$w$} (\pdew,1);

\end{tikzpicture}
\caption{Discarding-Speicherlayout}
\label{fig:doubling:opt:discard}
\end{figure}

\subsection{Beispiel}

Wir stellen nun die Funktionsweise des Discarding-Algorithmus ohne Optimierungen anhand des Beispieltextes \texttt{caabaccaabacaa\$} vor:

\input{kapitel/saca_algorithmen/prefix_doubling/prefix_doubling_example}

\subsection{Optimierungen}
\label{algo:doubling:sec:usedoptimizations}

Es wurden eine Reihe von Optimierungen durchgeführt, um den Speicherverbrauch und die Laufzeitperformance der anfänglichen Implementierung zu verbessern:

\subsubsection{Array-Überlagerung beim Doubling} Die ausschlaggebendste Speicheroptimierung basiert auf der Beobachtung, dass die Algorithmen nie gleichzeitig auf alle Elemente der benutzen Arrays zugreifen müssen.

Betrachten wir hierzu zunächst $P$ und $S$ des einfachen Doubling-Algorithmus~\ref{algo:doubling:code:doubling}. Aus den Überlegungen zum Pipelining wissen wir, dass das Erzeugen der umbenannten Tupel in Zeile 5 online während der Iteration über die Elemente von $S$ geschehen kann. Dasselbe gilt umgekehrt für die Paarbildung in Zeile 11--14, bei der wir für das $i$-te Paar nur jeweils den $i$-ten und $i+1$-ten Eintrag aus $P$ benötigen. 

Wir beobachteten außerdem, dass sich die Tupel $(c, i) \in P$ vollständig als Tupel $((c_1, \dots, c_a), i) \in S$ darstellen lassen, indem wir zB. $c$ immer durch $c_1$ repräsentieren.

Wir repräsentieren $P$ und $S$ nun nicht mehr durch zwei getrennte Arrays der Länge $(a + 1)nw$ für $S$ und $2nw$ für $P$, sondern nutzen ein einzelnes Array $SP$ der Größe $(a + 1)nw$  bei dem ein Eintrag \textit{entweder} ein Tupel $(c, i) \in P$ \textit{oder} ein Tupel $((c_1, \dots, c_a), i) \in S$ enthält. Die Umbenennung bzw. Paarbildung im Algorithmus iteriert somit durch ein Array aus anfänglich $S$ bzw. $P$ Elementen und ersetzt dabei sequentiell jeden Eintrag durch das errechnete $P$ bzw. $S$ Element. Siehe \cref{fig:doubling:opt:lagerung}.

\begin{figure}
\begin{tikzpicture}[yscale=-1,xscale=\textwidth/(\pdew cm + 1cm)]

\def\pdegap{0.5}

% Arrays
\path (2, 0) rectangle coordinate (PSm) ($(\pdew, 4)$);

\coordinate (P1start) at (2, 2);
\coordinate (P1end) at (\pdew, 4);

\coordinate (S1start) at (2, 0);
\coordinate (S1end) at (\pdew, 4);

\draw [black,fill=blue!20] (P1start) rectangle coordinate (P1) ($(PSm |- P1end) - (\pdegap, 0)$);
\draw [black,fill=green!20] ($(PSm |- S1start) + (\pdegap, 0)$) rectangle coordinate (S1) (S1end);

x% Komponents
\draw [black] (0, 2) rectangle coordinate (cP1) (1, 3);
\draw [black] (0, 3) rectangle coordinate (iPS1) (2, 4);

\draw [black] (1, 0) rectangle coordinate (cS1) (2, 3);

% Komponent lines
\draw [dashed] (2,0) -- (\pdew,0);
\draw [dashed] (2,1) -- (\pdew,1);
\draw [dashed] (2,2) -- (\pdew,2);
\draw [dashed] (2,3) -- (\pdew,3);
\draw [dashed] (2,4) -- (\pdew,4);

% Labels
\node[fill=blue!20] at (P1) {$P$};
\node[fill=green!20] at (S1) {$S$};

\node at (cP1) {$c$};
\node at (iPS1) {$i$};

\node at ($(cS1) - (0, 1)$)  {$c_1$};
\node at (cS1) {$\vdots$};
\node at ($(cS1) + (0, 1)$)  {$c_a$};

% Braces
\draw[decoration={brace,amplitude=10pt,raise=2pt},decorate]
  (2,0) -- node[above=12pt] {$n$} (\pdew,0);
  
\draw[decoration={brace,amplitude=5pt,raise=2pt},decorate]
  (\pdew,0) -- node[right=7pt] {$w$} (\pdew,1);
  
% Arrow
\coordinate (midbelow) at (PSm);

\node[single arrow, draw=black, fill=gray!50, minimum height=40] at(midbelow) {$c \leftarrow name(c_1, \dots, c_a)$};

\end{tikzpicture}
\caption{Doubling-Speicherlayout bei Array-Überlagerung}
\label{fig:doubling:opt:lagerung}
\end{figure}

\subsubsection{Array-Überlagerung beim Discarding} Die vorherige Optimierung lässt sich zunächst direkt auf die $S$ und $U$ Arrays der Discaring-Variante \ref{algo:doubling:code:discarding} anwenden, um den Speicherverbrauch auf $(a+5)nw$ Bytes zu senken.

Wir können jedoch noch weiter gehen. Hierzu schauen wir uns an, wie genau die Arrays $P$ und $F$ benutzt werden. In den Zeilen 14--26 wird für jeden Eintrag, den wir aus $U$ entfernen, entweder ein Element zu $F$, $P$, oder $S$ hinzugefügt. Es gilt somit zu jedem Zeitpunkt $|S| + |U| + |F| + |P| = n$. Dies gilt ebenso in den Zeilen 8--12 und 31, da die beteiligten Arrays immer um dieselbe Anzahl von Elementen erweitert und verringert werden.

Es ist somit erneut möglich, alle Arrays durch ein kombiniertes Array $SUPF$ der Größe $(a + 1)nw$ zu repräsentieren, indem jeder Eintrag entweder $S$, $U$, $P$ oder $F$ zugeordnet ist. Das Problem hierbei ist, dass wir nun in jedem Schritt des Algorithmus jeden Eintrag des kombinierten Arrays eindeutig einen der vier ursprünglichen Arrays zuordnen müssen und sie in denselben Laufzeitschranken wie zuvor iterieren und erweitern bzw. verkürzen wollen.

Wir lösen diese Problem in der Implementierung wie folgt:

\begin{enumerate}
\item Alle Elemente der Teil-Arrays $P$, $S$ und $U$ liegen immer konsekutiv in $SUPF$. Dies erlaubt es, die Arraygrenzen mit konstanten Platzverbrauch zu speichern und auf jedes Element in konstanter Zeit zuzugreifen.
\item Die Elemente von $F$ sind aufgeteilt in ein Teil-Array aller Elemente von vergangenen Iterationen und der der aktuellen Iteration. Beide Arrays werden nach jeder Iteration ohne zusätzliche Kosten vereint.
\item Teil-Arrays werden verkürzt, indem das erste oder letzte Element entfernt wird. Dies lässt eine leere Stelle zurück.
\item Teil-Arrays werden erweitert, indem ein Element in eine anliegende Stelle eingefügt wird. Liegt dort ein Element eines Nachbararrays, wird dieses rekursiv entfernt und an der anderen Seite eingefügt. Dies verschiebt das Nachbararray in konstanter Zeit um ein Element, aber erhält nicht seine Reihenfolge.
\item Teil-Arrays, die vereinigt oder ineinander umgewandelt werden liegen nebeneinander oder nehmen denselben Platz ein.
\end{enumerate}

Daraus folgt folgendes Layout von $SUPF$:

\begin{enumerate}
\item $P$ liegt am linken Rand, da dort die Reihenfolge wichtig ist und äußere Teil-Arrays nicht verschoben werden können.
\item $S$ liegt neben $P$, da es in $U$ umbenannt und danach mit $P$ vereinigt wird.
\item Neue $F$ Elemente liegen neben $S$
\item $U$ liegt rechts von neuen $F$ Elementen und links neben $F$-Elemente der vorherigen Iteration.
\item Das finale $F$ sammelt sich iterativ am rechten Rand von $SUPF$ und wird in jeder Iteration nach links um mögliche neue $F$ Elemente erweitert.
\end{enumerate}

Siehe \cref{fig:doubling:opt:discardlagerung} für ein Beispiel für den Zustand von $SUPF$ während Zeile 14--26 des Algorithmus. Diese Optimierung ermöglicht uns, den Speicherverbrauch von Discarding auf denselben Wert $(a + 1)nw$ wie für das normale Doubling zu reduzieren.

\begin{figure}
\begin{tikzpicture}[yscale=-1,xscale=\textwidth/(\pdew cm + 1cm)]

\def\pdegap{0.5}

% Arrays
\path (2, 0) rectangle coordinate (PSm) ($(\pdew, 4)$);

\coordinate (P1start) at (2, 2);
\coordinate (P1end) at (\pdew, 4);

\coordinate (S1start) at (2, 0);
\coordinate (S2start) at (6, 0);
\coordinate (S1end) at (\pdew, 4);

\coordinate (leftend) at ($(PSm |- P1end) - (\pdegap, 0)$);
\coordinate (rightend) at ($(PSm |- S1start) + (\pdegap, 2)$);

\draw [black,fill=blue!20] (2, 2) rectangle coordinate (P1) ++(3,2);
\draw [black,fill=green!20] (5,0) rectangle coordinate (S1) ++(4,4);
\draw [black,fill=red!20] (9, 2) rectangle coordinate (F1) (leftend);
\draw [black,fill=yellow!20] (rightend) rectangle coordinate (U1) ++(5,2);
\draw [black,fill=red!20] ($(rightend) + (5,0)$) rectangle coordinate (F2) (S1end);


x% Komponents
\draw [black] (0, 2) rectangle coordinate (cP1) (1, 3);
\draw [black] (0, 3) rectangle coordinate (iPS1) (2, 4);

\draw [black] (1, 0) rectangle coordinate (cS1) (2, 3);

% Komponent lines
\draw [dashed] (2,0) -- (\pdew,0);
\draw [dashed] (2,1) -- (\pdew,1);
\draw [dashed] (2,2) -- (\pdew,2);
\draw [dashed] (2,3) -- (\pdew,3);
\draw [dashed] (2,4) -- (\pdew,4);

% Labels
\node[fill=blue!20] at (P1) {$P$};
\node[fill=green!20] at (S1) {$S$};
\node[fill=red!20] at (F1) {$F_{new}$};
\node[fill=red!20] at (F2) {$F_{prev}$};
\node[fill=yellow!20] at (U1) {$U$};

\node at (cP1) {$c$};
\node at (iPS1) {$i$};

\node at ($(cS1) - (0, 1)$)  {$c_1$};
\node at (cS1) {$\vdots$};
\node at ($(cS1) + (0, 1)$)  {$c_a$};

% Braces
\draw[decoration={brace,amplitude=10pt,raise=2pt},decorate]
  (2,0) -- node[above=12pt] {$n$} (\pdew,0);
  
\draw[decoration={brace,amplitude=5pt,raise=2pt},decorate]
  (\pdew,0) -- node[right=7pt] {$w$} (\pdew,1);
  
% Arrow
\coordinate (midbelow) at (PSm);

\node[single arrow, draw=black, fill=gray!50, minimum height=40] at(midbelow) {Zeilen 14--26};
\node[single arrow, draw=black, fill=gray!50, minimum height=30] at(5,3.5) {};
\node[single arrow, draw=black, fill=gray!50, minimum height=30] at(9,3.5) {};

\end{tikzpicture}
\caption{Discarding-Speicherlayout bei Array-Überlagerung}
\label{fig:doubling:opt:discardlagerung}
\end{figure}

\subsubsection{Wordpacking}

Sowohl Doubling und Discarding erstellen eine initiale Version des $S$-Arrays, indem benachbarte Zeichen der Eingabe in den Tupeln $(c_1, \dots, c_a)$ als Namen benutzt werden. Da die Zeichen der Eingabe jedoch maximal ein Byte belegen und \texttt{sa\_index} aus $\ge 4$ Bytes besteht, enthält jeder $c_x$ in der ersten Iteration $\ge 3$ Nullbytes.

Die Idee des Wordpackings ist es, den Wertebereich der Namen $c_x$ voll auszunutzen, indem man sie aus der Konkatenation von benachbarten Eingabe-Bytes bildet. Die Namenstupel aus $S$ repräsentieren somit nicht mehr $a$ benachbarte Zeichen, sondern $aw$. Da gilt $w \ge 4$, erlaubt uns dies in der Regel die ersten Iterationen der Algorithmen zu überspringen. Da diese gerade beim Discarding auch die aufwändigsten sind, reduziert dies die Rechenzeit um einen signifikanten Anteil.

\subsubsection{Schnellerer Sortierschlüssel}

Alle Varianten der Algorithmen enthalten in der $k$-ten Iteration einen Sortierschritt, der Tupel $(c, i)$ gemäß des Sortierschlüssels $(i \mod 2^k, i \div 2^k)$ sortiert. Experimente basierend auf Profiling des kompilierten C++-Codes ergaben folgende Erkenntnisse:

\begin{enumerate}
\item Die Modulorechnung macht einen signifikanten Anteil der Sortierlaufzeit aus.
\item Ersetzt man sie für $a = 2$ oder $a = 4$ durch Bitshifting Operationen reduziert sich die Laufzeit auf $< 50\%$, aber sie machen immer noch einen signifikanten Anteil aus.
\end{enumerate}

Dies liegt darin begründet, dass wir neben den $\mathcal{O}(n \log n)$ Vergleichsoperationen auch $\mathcal{O}(n \log n)$ Rechenoperationen durchführen müssen, um die zu vergleichenden Integer-Werte zu erhalten. Eine Verringerung der Rechenkosten würde sich somit vorteilhaft auf die Laufzeit auswirken. Wir stellen nun folgendes fest:

\begin{enumerate}
\item Unmittelbar vor dem Sortierschritt wird eine Benennungsphase durchgeführt, die sequentiell alle $(c, i)$ Tupel erzeugt.
\item Unmittelbar nach dem Sortierschritt wird eine Paarbildungs- bzw. Discarding-Phase durchgeführt, die sequentiell alle sortierten $(c, i)$ Tupel verarbeitet.
\item Die Tupel $(i \mod 2^k, i \div 2^k)$ lassen sich für $a = 2$ oder $a = 4$ als eine Bitrotation des Integers $i$ in der gleichen Anzahl von Bits repräsentieren und erhalten dabei dieselbe Ordnung untereinander. Wir bezeichnen diese Repräsentation als $i_{rot}$
\end{enumerate}

Dies ermöglicht es uns die Rechenoperationen auf $\mathcal{O}(n)$ zu senken, indem wir die Tupeltransformation nicht während der Sortierung durchführen, sondern als Vor- bzw. Nachbearbeitungsschritt während der direkt anliegenden Phasen. Konkret führen wir folgende Modifikation durch:

\begin{itemize}
\item Für jedes $(c, i)$ Tupel, das die Benennungsphase erzeugt, berechnen und speichern wir $(c, i_{rot})$ im zugehörigen Array.
\item Die Sortierphase sortiert die $(c, i_{rot})$ Tupel anhand $i_{rot}$ gemäß der natürlichen Ordnung auf $\mathbb{N}$.
\item Die anschließende Paarbildungs- bzw. Discarding-Phase transformiert die sortierten $(c, i_{rot})$ Tupel zurück zu den ursprünglichen $(c, i)$ Tupeln und verarbeitet sie dann normal weiter.
\end{itemize}

\subsubsection{In-Place-Merging}

Der Discarding-Algorithmus \ref{algo:doubling:code:doubling} führt in Zeile 10 einen Merge-Schritt zwischen den $P$- und $U$-Arrays durch, nachdem $U$ gemäß des Sortierschlüssels für $k$ sortiert wurde. 

Da ein einfacher Merge-Schritt zusätzlichen Speicher benötigt, erfolgt dies in der anfänglichen Implementierung durch eine simple Konkatenation von $P$ mit $U$ \textit{vor} der Sortierung. Die Laufzeit beträgt somit $\mathcal{O}( (|P| + |U|) \log (|P| + |U|))$, anstatt $\mathcal{O}( |U| + |P| + |U| \log |U|)$.

Als Optimierung wurde deshalb an dieser Stelle ein In-Place-Merge-Algorithmus implementiert. Es wurde dabei ausgenutzt, dass durch die Array-Überlagerung in den zu vereinigenden Arrays $U$ und $P$ unbenutzte freie Tupelkomponenten vorhanden sind.

Diese werden als zusätzliches Array der Länge $|U| + |P|$ mit Platz für $a - 1$ Elemente pro Position interpretiert und genutzt um die $(c, i)$-Tupel von $P$ und dem sortierten $U$ in $\mathcal{O}( |U| + |P|)$ zu vereinigen. Für $a=2$ sind dabei zwei Scans notwendig, da nicht beide Komponenten der Tupel gleichzeitig an eine freie Stelle kopiert werden können.

\subsubsection{Schnellerer Sortieralgorithmus}

Da unsere Implementierung nur im Arbeitsspeicher arbeitet, sind wir nicht an einen bestimmten extern arbeitenden Sortieralgorithmus gebunden, weshalb es uns frei steht einen Sortierer zu nutzen, der das beste Laufzeitverhalten zeigt.

Wir haben hierzu den Discarding-Algorithmus mit allen im Framework verfügbaren Sortierern auf einer Reihe von Testdaten angewandt, um dem sich empirisch am besten verhaltenden Algorithmus zu wählen. Es stellte sich hierbei der externe \ipsviero Algorithmus (siehe \cref{section:ips4o}) als mit Abstand bester Algorithmus heraus.

\subsubsection{Ausgelassene Optimierungsansätze}

Da der Ausgabe-\texttt{span} zu einer Allokation von mindestens $n \log n$ Bits zeigt, würde er sich im Prinzip als temporären Speicher für eine der Komponenten der von dem Algorithmus benutzten Tupel-Arrays benutzen lassen, um den Speicherverbrauch während der Berechnung um denselben Wert zu senken. 

Dies würde jedoch die Implementierung wesentlich komplexer machen, da die Komponenten eines Tupels nun über mehrere disjunkte \texttt{span}s verteilt wären. Da das Interface der Sortierer-Implementierungen darauf beruht, nur vollständige Elemente eines Arrays zu sortieren, wäre somit also auch eine Anpassung der benutzten Sortieralgorithmen notwendig.

\subsection{Parallelisierung}
\label{chapter:saca:doubling:par}

Alle vorgestellten Varianten des Algorithmus lassen sich trivial parallelisieren, indem ein paralleler Sortieralgorithmus benutzt wird. Wir nutzen hierzu den parallelen \ipsviero Algorithmus aus \cref{section:ips4o}.

In anderen Aspekten ist eine parallelisieren der Algorithmen nicht effektiv möglich, da sowohl die Umbenennungsphase als auch die Paarbildungsphase inhärent sequentielle Abläufe beinhalten.
